Title: I hear Steve Jobs laughing
Subtitle: and other developments as of October 15
Author: Peter Schoppert
URL: https://aicopyright.substack.com/p/i-hear-steve-jobs-laughing
---
_A weekly email update on developments in the world of Foundation Models (I’m going with that terminology now), with a specific focus on the question of how the legal uncertainty around these models will be sorted. For more background, please read[here.](https://aicopyright.substack.com/about)_

### Publishing in Play in the House of Lords 

On Tuesday 11 October, the Publishers Association CEO Dan Conway [answered questions from the UK House of Lords Communications and Digital Committee](https://parliamentlive.tv/event/index/36ce838f-eb8d-4a47-91d2-9d20eb1d2180), alongside Paul Fleming, General Secretary at Equity, the union representing workers in the performing arts sector, and Dr. Andres Guadamuz, Reader in Intellectual Property Law, University of Sussex. The topic was the impact of AI on the creative industries.

Thanks for reading AI and Copyright! Subscribe for free to receive new posts and support my work.

Subscribe

For the last two years at least, since their 2020 report [People Plus Machines](https://publishers-association.shorthandstories.com/people-plus-machines/index.html), PA’s strategy has been to show how the publishing industry are enthusiastic users of AI. In recent months, the PA has expressed opposition to the UK’s proposed widening of the TDM exception to cover commercial activity, on the grounds that it will inhibit the investment in data which is crucial for AI’s forward progress and alignment with human intent (as the AI folks [put it](https://arxiv.org/abs/2203.02155)!). 

Accordingly, Conway’s opening statement portrayed AI as entirely positive to the creative industries. He made the surprising claim that AI had not affected the labour market in the publishing industry.[1](https://aicopyright.substack.com/p/i-hear-steve-jobs-laughing#footnote-1-78576991) He also risked coming off a bit three-martini by seeming to endorse the “AI cannot possibly replace the creativity of literary writers and publishers” view, one which risks denying the Foundation Models’ potential impact. Even a few of the Lords had to question him on this…

To me the hearing showed the necessity of breaking the discussion on AI into component parts, considering 2020’s data-sensitive supervised and unsupervised learning in one bucket, and the new world of the Foundation Models in another. The PA’s work and perspective considers the first sort of AI very deeply, but Conway’s testimony did not show signs of reckoning with the second. Dr Guadamuz did his best to point to the incredible speed, novelty and importance of the latter.

Equity’s Fleming was very focused on the implications of AI for his members, individual workers rather than corporates, and he was accordingly up-to-date on the outputs of AI, and the impact that had on actors, composers and other creatives. 

#### making exceptions

Conway was strong and sharp in his opposition to the IPO’s [recent advice](https://www.gov.uk/government/consultations/artificial-intelligence-and-ip-copyright-and-patents/outcome/artificial-intelligence-and-intellectual-property-copyright-and-patents-government-response-to-consultation) that UK broaden the TDM exception. 

He put it this way (pardon the imperfect human transcription/paraphase - my Otter.ai free plan hit its limit before this point, and the official transcription is not yet released): “we have a research exception, as has been described by Dr Guadamuz, so if you are doing research you can copy whatever data you need. But if you are going to commercialise that research, you have to pay a licensing fee to do so. And in a market, that feels fair, as long as that licensing agreement process is working. We think it's working. We’ve measured that market as GBP 350m per year for our members, and growing, unless of course there is an exception that undermines it.”

Very true for last year’s TDM that was about feeding carefully curated datasets to supervised and unsupervised learning systems of smaller size, highly sensitive to variations in the data. But the Foundation Models are trained on huge indiscrimate piles of (mostly copyrighted) material and their creators have completely ignored the possibility (and arguably need) to license data. The builders of these models believe that it would be impossible to license the vast amounts of data they need. 

Remember too that [in last week’s newsletter](https://aicopyright.substack.com/p/how-big-tech-is-exploiting-existing) we’ve seen that non-profit groups do copying under the existing UK research exception, with the computing paid for by grants from for-profit entities. In fact Dr Guadamuz highlighted the group in question, UK-based Stability.ai, company behind Stable Diffusion, which raised US$100m on a valuation of US$1 billion for their image synthesizer, based on the existing legal position. He didn’t give a view on the legality/morality of the research/commercial bait-and-switch. Of course the PA should fight the proposed exception, but the fact remains that the research / commercial distinction is being ignored in practice, at least for the Foundation Models. **The licensing model** _ **is not working**_ **in this most important of cases.**

#### a new forum

Conway had a good exchange with committee member Baroness Rebuck[2](https://aicopyright.substack.com/p/i-hear-steve-jobs-laughing#footnote-2-78576991). Well it should have been a good exchange as Baroness Rebuck is otherwise known as Gail Rebuck, chair of Penguin Random House UK, and therefore one of Conway’s key stakeholders. They agreed that it would be a very good idea for policy-makers to convene an ongoing forum between academia, the creative industries, tech and government that looked at how AI worked in a more holistic way. This would be better, said Conway, “than having the piecemeal conversations we feel we're having at the moment.” Absolutely agree on this point! 

You can watch the whole session [here](https://parliamentlive.tv/event/index/36ce838f-eb8d-4a47-91d2-9d20eb1d2180). 

#### And what about the robot?

I outsourced watching the testimony of ~~publicity gimmick~~ robot to _The Guardian’s_ Alex Hearn, who’s report was headlined [“](https://www.theguardian.com/technology/2022/oct/14/ai-da-robot-sums-up-flawed-logic-lords-debate-ai) **[Ai-Da the robot sums up the flawed logic of Lords debate on AI.”](https://www.theguardian.com/technology/2022/oct/14/ai-da-robot-sums-up-flawed-logic-lords-debate-ai) **

> Apparently overcome by the stuffy atmosphere, the machine, which resembles a sex doll strapped to a pair of egg whisks, shut down halfway through the evidence session. As its creator, Aidan Meller, scrabbled with power sockets to restart the device, he put a pair of sunglasses on the machine. “When we reset her, she can sometimes pull quite interesting faces,” he explained.

Hearn’s report is recommended: he also mentions the data-laundering point above.

#### message development

I do think publishers need to update their kitbag with a separate set of messages around the Foundation Models:

  1. The Foundation Models are a different sort of AI. They are different in scale, capability and how they were created. They can be combined and tuned in different ways, and represent a new, well, foundational, set of technologies. 

  2. the Foundation Models were **created on the basis of unauthorized copying** of copyrighted material, including infringing material _and_ material that was legally accessed. This is only one of the many valid questions about the data that goes into these models.

  3. even at this very early stage, the **Foundation Models are starting to impact, narrow and substitute markets for creative work,** and this substitution and narrowing will only increase as the tools are further developed. Of course AI is also yielding tools that will be of immense benefit to creators and the creative industries, but see point 1 above, and the more general need to reckon with this new power.




### Zooming ahead with Foundation Models

Meanwhile, the field continues to zoom ahead. Given the time I spent listening to the Lords hearing, I have just a few examples for this week’s newsletter:

#### visual narrative film from sentences of text

Only a week ago, researchers unveiled a system that generates a few seconds of video based on a text prompt. New work enables a text-to-video system to produce an entire visual narrative from several sentences of text.

Google’s Phenaki produces videos of arbitrary length from a story-like description. See examples at [https://phenaki.github.io/.](https://phenaki.github.io/)

#### improved voice synthesis + GPT-3 brings Steve Jobs back

Check out t[his podcast interview](https://podcast.ai/) with Steve Jobs. (Looks like the site may be done from all the traffic - this has been widely covered in media…)

This is built on [a new approach](http://ai.googleblog.com/2022/10/audiolm-language-modeling-approach-to.html) from Google on modelling speech, one that is trained without text, and so “captures those aspects of speech that cannot be transcribed”. It incorporates completely all the uhms and ahems (and likes!) that makes speech believable.

 _You need to hear AI Steve Jobs laughing…_

#### [Microsoft brings DALL-E into Microsoft Office](https://www.theverge.com/2022/10/12/23400270/ai-generated-art-dall-e-microsoft-designer-app-office-365-suite)

 _No impact on the labour market for the creative industries?_

[1](https://aicopyright.substack.com/p/i-hear-steve-jobs-laughing#footnote-anchor-1-78576991)

Tell that to translators and freelance illustrators (and soon copy editors), but then the PA represents publishing companies not publishing workers, and UK publishers have been outsourcing editorial and prepress work for decades now. 

[2](https://aicopyright.substack.com/p/i-hear-steve-jobs-laughing#footnote-anchor-2-78576991)

I’m _pretty_ sure it was Baroness Rebuck, the video and audio were not very clear…
