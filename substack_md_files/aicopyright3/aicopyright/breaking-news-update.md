Title: Breaking News Update
Subtitle: new lawsuit in UK, the human labor behind OpenAI's model patching, and a first read of the Ortiz et al class action
Author: Peter Schoppert
URL: https://aicopyright.substack.com/p/breaking-news-update
---
### First, a second lawsuit.

From the Getty Images press statement:

Thanks for reading AI and Copyright! Subscribe for free to receive new posts and support my work.

Subscribe

> “This week Getty Images commenced legal proceedings in the High Court of Justice in London against Stability AI claiming Stability AI infringed intellectual property rights including copyright in content owned or represented by Getty Images. It is Getty Images’ position that Stability AI unlawfully copied and processed millions of images protected by copyright and the associated metadata owned or represented by Getty Images absent a license to benefit Stability AI’s commercial interests and to the detriment of the content creators.”

It’s a UK lawsuit, so it seems Getty does not believe the existing TDM exception will protect Stability AI. James Vincent’s [report in the Verge](https://www.theverge.com/2023/1/17/23558516/ai-art-copyright-stable-diffusion-getty-images-lawsuit) says that while details of the suit have not been made public “charges include copyright violation and violation of the site’s terms of service (in particular, web scraping).”

### Secondly, some excellent reporting from Time magazine, 

with this headline [“OpenAI Used Kenyan Workers on Less Than $2 Per Hour to Make ChatGPT Less Toxic”](https://time.com/6247678/openai-chatgpt-kenya-workers/). One of the least open things about “Open”AI is how untransparent they are about the model-patching they do, in particular the ways they filter Foundation Model output to avoid prejudice, harm and reproducing copyrighted content. Well it turns out that human labour was essential to building filters — both for training material and for outputs — to avoid harm. But that meant exposing contract workers to child porn and excessively violent and deeply shocking images. Facebook’s moderation problem leveraged to the nth degree.

Subscribe

### and meanwhile, reading the Ortiz et al complaint

[This class action, ](https://stablediffusionlitigation.com/pdf/00201/1-1-stable-diffusion-complaint.pdf)unlike the Copilot/Github lawsuit, does include copyright violation among its complaints, indeed, as its first. Here are the complaints:

  1.  **DIRECT COPYRIGHT INFRINGEMENT,** in copying for training, _and_ incorporated into the model, as well as by creating and distributing derivate works via the model, without license, for profit and commercial purpose, and in market substitution of the plaintifs’ work, and negatively impacting their interests

  2.  **VICARIOUS COPYRIGHT INFRINGEMENT,** by individuals using the tools to imitate and create derivatives of the plaintiff’s works

  3.  **VIOLATION of the DIGITAL MILLENNIUM COPYRIGHT ACT,** in removing or altering copyright management information, as defined in the act

  4.  **VIOLATION of the STATUTORY RIGHT of PUBLICITY,** by “appropriating Plaintiffs’ names for Defendants’ advantage”, 

  5. **VIOLATION of the COMMON LAW RIGHT of PUBLICITY,** not only misappropriating works, but also Plaintiffs’ names and artistic identities

  6.  **UNFAIR COMPETITION**

  7.  **BREACH of CONTRACT VIOLATION of DEVIANTART POLICIES.** This section was to me the most shocking reading in the complaint, the way Deviant Art changed the terms of use _after_ introducing its own AI tool based on StableDiffusion, which had been trained on millions of images on the DeviantArt website.




Lots to talk about from within the complaint itself, but I’ll save that for the upcoming weekend edition. Just to say the characterization of the way the model works will be a key point of contention, as previewed in last week’s edition.

[Share](https://aicopyright.substack.com/p/breaking-news-update?utm_source=substack&utm_medium=email&utm_content=share&action=share)

Thanks for reading AI and Copyright! Subscribe for free to receive new posts and support my work.

Subscribe
